# Neo4j Configuration
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=graphrag
NEO4J_HOME=~/.local/neo4j
NEO4J_DATA_DIR=~/.graphrag/neo4j

# Note: Port 7687 is for local Neo4j, port 7688 is for Docker mapping (see docker-compose.yml)

# ChromaDB Configuration
CHROMA_PERSIST_DIRECTORY=./data/chromadb

# API Configuration
GRAPHRAG_API_PORT=5001
GRAPHRAG_MPC_PORT=8765

# LLM Configuration
LLM_ENDPOINT=http://192.168.1.21:1234  # Local LM Studio endpoint for Phi-4
OLLAMA_ENDPOINT=http://localhost:11434  # Local Ollama endpoint
EMBEDDING_MODEL=snowflake-arctic-embed2:latest  # Default embedding model
RERANKER_MODEL=qllama/bge-reranker-large:latest  # Optional reranker model
CONCEPT_MODEL=lmstudio-community/Phi-4-mini-reasoning-MLX-4bit  # Model for concept extraction
USE_LOCAL_LLM=true