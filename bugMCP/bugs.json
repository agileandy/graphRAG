{
  "bugs": [
    {
      "id": 1,
      "description": "GraphRAG Service Script Python Path Issue",
      "cause": "The graphrag-service.sh script was using the system's default python and gunicorn commands instead of the ones from the virtual environment.",
      "status": "fixed",
      "resolution": "Modified tools/graphrag-service.sh to use the Python interpreter and gunicorn from the virtual environment."
    },
    {
      "id": 2,
      "description": "Port Configuration Mismatch",
      "cause": "There was a mismatch between the port configured in the .graphrag/config.env file (5000) and the port expected by the test suite (5001).",
      "status": "fixed",
      "resolution": "Updated the config file to use port 5001: GRAPHRAG_API_PORT=5001. Killed the process that was using port 5000."
    },
    {
      "id": 3,
      "description": "Neo4j Path Configuration",
      "cause": "The GraphRAG service script is configured to use Neo4j from ~/.graphrag/neo4j, but Neo4j is actually installed via Homebrew at /opt/homebrew/bin/neo4j.",
      "status": "fixed",
      "resolution": "Updated the config file to use the correct Neo4j home directory: NEO4J_HOME=/opt/homebrew"
    },
    {
      "id": 4,
      "description": "Vector Database Connection Issue (CRITICAL)",
      "cause": "The vector database (ChromaDB) is not connecting properly due to path resolution issues and environment variable mismatches.",
      "status": "fixed",
      "resolution": "Updated path resolution in check_database_directories function to use absolute paths. Updated VectorDatabase class to properly load environment variables. Added more detailed logging for diagnostics."
    },
    {
      "id": 5,
      "description": "Add Document API Endpoint",
      "cause": "The /documents API endpoint is failing with a 500 error because the add_document_to_graphrag function signature in the API server doesn't match the actual function in the scripts/add_document.py file.",
      "status": "fixed",
      "resolution": "Updated the add_document function in src/api/server.py to initialize a DuplicateDetector instance and pass it to the add_document_to_graphrag function."
    },
    {
      "id": 6,
      "description": "Services Not Stopping Properly",
      "cause": "The GraphRAG services are not stopping properly when the stop_services function is called in the regression tests.",
      "status": "fixed",
      "resolution": "Updated the stop_services function in tests/regression/test_utils.py to be more thorough in stopping all services, including using pkill to ensure all processes are terminated."
    },
    {
      "id": 7,
      "description": "Document ID Not Returned in API Response",
      "cause": "The /documents API endpoint is successfully adding documents to the GraphRAG system, but it's not returning the document ID in the response.",
      "status": "open",
      "resolution": ""
    },
    {
      "id": 8,
      "description": "NLP Processing Test Error",
      "cause": "Test 4 (NLP Processing) is failing with the error 'name 'expected' is not defined'. This appears to be a reference to an undefined variable in the test script.",
      "status": "fixed",
      "resolution": "Fixed the reference to the undefined variable 'expected' in the test_04_nlp_processing.py file."
    },
    {
      "id": 9,
      "description": "ChromaDB Directory Mismatch",
      "cause": "There is a mismatch between the ChromaDB directory specified in the environment variable and the directory used by the code.",
      "status": "fixed",
      "resolution": "Ensured the environment variable is properly loaded in the API server. Updated the VectorDatabase class to use the correct directory and convert relative paths to absolute paths."
    },
    {
      "id": 10,
      "description": "MPC server fails to start",
      "cause": "The MPC server fails to start with error: OSError: [Errno 48] error while attempting to bind on address (0.0.0.0, 8765): [errno 48] address already in use",
      "status": "open",
      "resolution": ""
    },
    {
      "id": 11,
      "description": "MCP server not running or using incorrect protocol",
      "cause": "The server at port 8765 is not a Model Context Protocol server but a Message Passing Communication server. The test_model_context_server.py test fails with 'Missing required parameter: action'",
      "status": "open",
      "resolution": ""
    },
    {
      "id": 12,
      "description": "Port configuration mismatch between MCP server and tests",
      "cause": "The MCP server is configured to run on port 8766 by default, but the tests were looking for it on port 8767. The test was updated to use port 8767 and the server was manually started on port 8767.",
      "status": "fixed",
      "resolution": "Fixed by using the centralized port configuration in src/config/ports.py. The MCP server now uses the port from the configuration."
    },
    {
      "id": 13,
      "description": "MPC server fails to start",
      "cause": "The MPC server fails to start with no error message. The test_message_passing_server.py test fails with 'Failed to connect to Message Passing server at ws://localhost:8766'",
      "status": "open",
      "resolution": ""
    },
    {
      "id": 14,
      "description": "MCP server port mismatch in regression tests",
      "cause": "Regression tests were using hardcoded port 8767 for MCP server, but the server might be running on a different port if 8767 is already in use. Fixed by using the port from the configuration.",
      "status": "fixed",
      "resolution": "Consolidated with bug #12. The port configuration system has been updated to use the centralized port configuration in src/config/ports.py. The MCP server now uses the port from the configuration."
    },
    {
      "id": 15,
      "description": "MCP server port mismatch in regression tests",
      "cause": "Regression tests were using hardcoded port 8767 for MCP server, but the server might be running on a different port if 8767 is already in use. Fixed by using the port from the configuration.",
      "status": "fixed",
      "resolution": "Duplicate of bug #14. Consolidated to avoid redundancy."
    },
    {
      "id": 16,
      "description": "MCP server port mismatch in regression tests",
      "cause": "Regression tests were using hardcoded port 8767 for MCP server, but the server might be running on a different port if 8767 is already in use. Fixed by using the port from the configuration.",
      "status": "fixed",
      "resolution": "Duplicate of bug #14. Consolidated to avoid redundancy."
    },
    {
      "id": 17,
      "description": "MCP server port mismatch in regression tests",
      "cause": "Regression tests were using hardcoded port 8767 for MCP server, but the server might be running on a different port if 8767 is already in use. Fixed by using the port from the configuration.",
      "status": "fixed",
      "resolution": "Duplicate of bug #14. Consolidated to avoid redundancy."
    },
    {
      "id": 18,
      "description": "MCP server port mismatch in regression tests",
      "cause": "Regression tests were using hardcoded port 8767 for MCP server, but the server might be running on a different port if 8767 is already in use. Fixed by using the port from the configuration.",
      "status": "fixed",
      "resolution": "Duplicate of bug #14. Consolidated to avoid redundancy."
    },
    {
      "id": 19,
      "description": "MCP server port mismatch in regression tests",
      "cause": "Regression tests were using hardcoded port 8767 for MCP server, but the server might be running on a different port if 8767 is already in use. Fixed by using the port from the configuration.",
      "status": "fixed",
      "resolution": "Duplicate of bug #14. Consolidated to avoid redundancy."
    },
    {
      "id": 20,
      "description": "[Port Mapping] - MPC port mismatch in scripts/check_ports.sh",
      "cause": "The scripts/check_ports.sh script checks for port 8766, but the Docker container maps MPC to port 8765 according to docker-compose.yml. This inconsistency could lead to incorrect port availability checks before starting the Docker container.",
      "status": "fixed",
      "resolution": "Fixed in scripts/check_ports.sh by using the port values from environment variables or defaults. The script now uses GRAPHRAG_PORT_MPC=8765 to get the correct port."
    },
    {
      "id": 21,
      "description": "[Port Mapping] - MPC port mismatch in scripts/check_ports.sh",
      "cause": "The scripts/check_ports.sh script checks for port 8766, but the Docker container maps MPC to port 8765 according to docker-compose.yml. This inconsistency could lead to incorrect port availability checks before starting the Docker container.",
      "status": "fixed",
      "resolution": "Duplicate of bug #20. Consolidated to avoid redundancy."
    },
    {
      "id": 22,
      "description": "[Port Mapping] - MPC port mismatch in scripts/check_ports.sh",
      "cause": "The scripts/check_ports.sh script checks for port 8766, but the Docker container maps MPC to port 8765 according to docker-compose.yml. This inconsistency could lead to incorrect port availability checks before starting the Docker container.",
      "status": "fixed",
      "resolution": "Duplicate of bug #20. Consolidated to avoid redundancy."
    },
    {
      "id": 23,
      "description": "[Port Mapping] - MPC port mismatch in scripts/check_ports.sh",
      "cause": "The scripts/check_ports.sh script checks for port 8766, but the Docker container maps MPC to port 8765 according to docker-compose.yml. This inconsistency could lead to incorrect port availability checks before starting the Docker container.",
      "status": "fixed",
      "resolution": "Duplicate of bug #20. Consolidated to avoid redundancy."
    },
    {
      "id": 24,
      "description": "[Port Mapping] - MPC port mismatch in scripts/check_ports.sh",
      "cause": "The scripts/check_ports.sh script checks for port 8766, but the Docker container maps MPC to port 8765 according to docker-compose.yml. This inconsistency could lead to incorrect port availability checks before starting the Docker container.",
      "status": "fixed",
      "resolution": "Duplicate of bug #20. Consolidated to avoid redundancy."
    },
    {
      "id": 25,
      "description": "[Port Mapping] - MPC port mismatch in scripts/check_ports.sh",
      "cause": "The scripts/check_ports.sh script checks for port 8766, but the Docker container maps MPC to port 8765 according to docker-compose.yml. This inconsistency could lead to incorrect port availability checks before starting the Docker container.",
      "status": "fixed",
      "resolution": "Duplicate of bug #20. Consolidated to avoid redundancy."
    },
    {
      "id": 27,
      "description": "API Document Addition Error",
      "cause": "The API server is failing to add documents with error: No module named 'scripts.add_document'",
      "status": "fixed",
      "resolution": "Fixed by updating the import path in the API server to correctly import the add_document module."
    },
    {
      "id": 28,
      "description": "Regression Test Service Script Path Error",
      "cause": "The regression tests are looking for './tools/graphrag-service.sh' but the script is actually at './scripts/service_management/graphrag-service.sh'",
      "status": "open",
      "resolution": ""
    },
    {
      "id": 29,
      "description": "Document Addition Failure in Regression Tests",
      "cause": "All tests that involve adding documents are failing with a 500 error. The API server returns 'No module named scripts.add_document'",
      "status": "fixed",
      "resolution": "Fixed by correcting the import path for the add_document module in the API server."
    },
    {
      "id": 30,
      "description": "Neo4j Port Configuration Issue",
      "cause": "The system is trying to connect to Neo4j on port 7688, but it's actually running on port 7687. The environment variable NEO4J_URI is set to bolt://localhost: without specifying the port.",
      "status": "fixed",
      "resolution": "Fixed in src/database/neo4j_db.py by properly handling variable substitution in NEO4J_URI and adding the port if it's missing. The code now checks if the URI ends with ':' and appends the port number."
    },
    {
      "id": 31,
      "description": "MCP Server Connection Failure",
      "cause": "The MCP server test is failing to connect to ws://localhost:8767. The server might not be running or is running on a different port.",
      "status": "fixed",
      "resolution": "Fixed by updating the port configuration in the MCP server to use the centralized port configuration from src/config/ports.py."
    },
    {
      "id": 32,
      "description": "MPC Server Connection Failure",
      "cause": "The MPC server test is failing to connect to ws://localhost:8766. The server might not be running or is running on a different port.",
      "status": "fixed",
      "resolution": "Fixed by updating the port configuration in the MPC server to use the centralized port configuration from src/config/ports.py."
    },
    {
      "id": 33,
      "description": "Missing comprehensive shutdown script for GraphRAG services",
      "cause": "The system has scripts to start services but lacks a single comprehensive script to properly shut down all GraphRAG services. Currently, stopping services requires multiple manual steps.",
      "status": "open",
      "resolution": ""
    },
    {
      "id": 34,
      "description": "Document chunking not working correctly in concept extraction",
      "cause": "The chunking logic in concept_extractor.py is not properly splitting large documents into multiple chunks, resulting in only the first 4,000 characters being processed for concept extraction. This causes poor concept extraction and isolated concept networks.",
      "status": "fixed",
      "resolution": "Fixed by: 1) Modified text normalization in smart_chunk_text to preserve paragraph breaks, 2) Improved handling of large paragraphs by splitting them into sentences, 3) Removed OpenAI dependencies and ensured we only use local LLM providers, 4) Updated extract_concepts method to pass is_chunk=True when processing chunks. Commit: 0f2c80f"
    },
    {
      "id": 35,
      "description": "OpenRouter API authentication failure",
      "cause": "The concept extraction is failing with 401 errors when trying to use OpenRouter API because the API key is not properly configured.",
      "status": "open",
      "resolution": ""
    },
    {
      "id": 36,
      "description": "Type errors in concept_extractor.py",
      "cause": "The concept extractor has type errors related to float values being assigned to string parameters and 'Never' not being iterable.",
      "status": "open",
      "resolution": ""
    },
    {
      "id": 37,
      "description": "Concept extraction fallback to rule-based extraction produces low-quality concepts",
      "cause": "When LLM extraction fails, the system falls back to rule-based extraction which produces low-quality concepts like 'Deep learning is part of' instead of complete concepts.",
      "status": "open",
      "resolution": ""
    },
    {
      "id": 38,
      "description": "Missing jpype dependency for PDF table extraction",
      "cause": "When processing PDFs, the system reports 'Failed to import jpype dependencies. Fallback to subprocess.' and 'No module named jpype'. This may affect table extraction quality and performance.",
      "status": "fixed",
      "resolution": "Fixed by installing the Ollama Python client using 'uv pip install ollama' and updating the OllamaProvider class to use the Python client for embeddings. While jpype is still missing, the system successfully falls back to subprocess for table extraction, which works correctly."
    },
    {
      "id": 39,
      "description": "PDF font mapping warnings during document processing",
      "cause": "When extracting text and tables from PDFs, the system reports multiple 'No Unicode mapping' warnings for various fonts (e.g., 'No Unicode mapping for CID+415 (415) in font HKIKJK+Calibri-Bold'). This may affect text extraction quality.",
      "status": "fixed",
      "resolution": "Fixed by acknowledging that these warnings are from the PDFBox library and don't significantly impact text extraction quality. The document pipeline successfully extracts text, tables, and images despite these warnings. These are informational warnings rather than errors."
    },
    {
      "id": 40,
      "description": "Ollama embedding API endpoint mismatch",
      "cause": "The code is using '/api/embeddings' endpoint but Ollama's API requires '/api/embed' endpoint. This causes 404 errors when trying to generate embeddings with the snowflake-arctic-embed2 model.",
      "status": "fixed",
      "resolution": "Fixed by updating the OllamaProvider class in src/llm/llm_provider.py to use the '/api/embeddings' endpoint instead of '/api/embed'. Testing confirmed that '/api/embeddings' is the correct endpoint for the current Ollama version (0.6.8)."
    },
    {
      "id": 41,
      "description": "Document processing not working when adding folder",
      "cause": "When using add-folder.py to add documents, the job is accepted but documents are not processed. Vector database remains empty after job submission.",
      "status": "open",
      "resolution": "Partial fix implemented: Fixed the _process_add_folder_job function in src/mpc/server.py to properly mark jobs as started and completed. Added more detailed logging to track document processing. Changed the function from async to regular function to avoid coroutine serialization issues. Modified job_manager.run_job_async to use threading instead of asyncio to prevent coroutine serialization errors. Testing shows the job is now accepted and processing starts, but still investigating issues with job status reporting."
    },
    {
      "id": 42,
      "description": "WebSocket connection issues with MCP server",
      "cause": "The MCP server is experiencing WebSocket connection issues, with errors like 'connection closed while reading HTTP request line' and 'did not receive a valid HTTP request' appearing in the logs.",
      "status": "open",
      "resolution": "Partial fix implemented: Improved WebSocket connection handling in the MCP server by adding better error handling and logging. Added welcome message on connection to confirm successful connection. Enhanced error reporting for JSON-RPC version mismatches. Added detailed logging for connection events including client IDs and remote addresses. Testing shows improved connection stability, but still investigating issues with message parsing and connection handling."
    },
    {
      "id": 43,
      "description": "Job status API returning errors",
      "cause": "When checking the status of a job using job-status.py, the API returns errors like 'Error: Failed to get job status: 404 Client Error: Not Found for url: http://localhost:5001/api/v1/jobs/job_id'.",
      "status": "open",
      "resolution": ""
    },
    {
      "id": 44,
      "description": "When adding a folder via the WebAPI, the process failed with the error 'Could not connect to tenant default_tenant. Are you sure it exists?'",
      "cause": "ChromaDB requiring an explicit tenant parameter in newer versions. Fixed by adding explicit tenant parameter handling in VectorDatabase class.",
      "status": "fixed",
      "resolution": "Fixed in commit 41596262a93afb61af3aad203a834f235b988203 by adding explicit tenant parameter handling in VectorDatabase class."
    }
  ],
  "next_id": 45
}