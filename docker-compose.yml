services:
  graphrag:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        VERSION: latest
    container_name: graphrag
    ports:
      # Neo4j Browser
      - "${GRAPHRAG_PORT_NEO4J_HTTP:-7474}:7474"
      # Neo4j Bolt
      - "${GRAPHRAG_PORT_DOCKER_NEO4J_BOLT:-7688}:7687"
      # API Server
      - "${GRAPHRAG_PORT_API:-5001}:5000"
      # MPC Server
      - "${GRAPHRAG_PORT_MPC:-8765}:8765"
      # MCP Server
      - "${GRAPHRAG_PORT_MCP:-8767}:8767"
    volumes:
      # Persist data
      - ./data:/app/data
      # Mount ebooks folder
      - /Users/andyspamer/ebooks:/app/ebooks
      # Mount source code for development
      - ./src:/app/src
      - ./scripts:/app/scripts
      - ./tools:/app/tools
    environment:
      # Port Configuration
      - GRAPHRAG_PORT_NEO4J_BOLT=7687
      - GRAPHRAG_PORT_NEO4J_HTTP=7474
      - GRAPHRAG_PORT_NEO4J_HTTPS=7473
      - GRAPHRAG_PORT_API=5000
      - GRAPHRAG_PORT_MPC=8765
      - GRAPHRAG_PORT_MCP=8767
      - GRAPHRAG_PORT_BUG_MCP=5005
      - GRAPHRAG_PORT_DOCKER_NEO4J_BOLT=7688

      # Neo4j Configuration (use 0.0.0.0 inside the container)
      - NEO4J_URI=bolt://0.0.0.0:${GRAPHRAG_PORT_NEO4J_BOLT}
      - NEO4J_USERNAME=neo4j
      - NEO4J_PASSWORD=graphrag
      - CHROMA_PERSIST_DIRECTORY=/app/data/chromadb

      # LLM Configuration
      - LLM_ENDPOINT=http://host.docker.internal:1234
      - OLLAMA_ENDPOINT=http://host.docker.internal:11434
      - EMBEDDING_MODEL=snowflake-arctic-embed2:latest
      - RERANKER_MODEL=qllama/bge-reranker-large:latest
      - CONCEPT_MODEL=lmstudio-community/Phi-4-mini-reasoning-MLX-4bit
      - USE_LOCAL_LLM=true

      # API URL (use 0.0.0.0 inside the container)
      - GRAPHRAG_API_URL=http://0.0.0.0:${GRAPHRAG_PORT_API}
      # Add your OpenAI API key here if needed
      # - OPENAI_API_KEY=your_openai_api_key
    restart: unless-stopped