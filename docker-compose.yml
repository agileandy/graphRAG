services:
  graphrag:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        VERSION: latest
    container_name: graphrag
    ports:
      # Neo4j Browser (changed from 7474 to 7475)
      - "7475:7474"
      # Neo4j Bolt (changed from 7687 to 7688)
      - "7688:7687"
      # API Server (changed from 5000 to 5001)
      - "5001:5000"
      # MPC Server (changed from 8765 to 8766)
      - "8766:8765"
    volumes:
      # Persist data
      - ./data:/app/data
      # Mount ebooks folder
      - /Users/andyspamer/ebooks:/app/ebooks
      # Mount source code for development
      - ./src:/app/src
      - ./scripts:/app/scripts
      - ./tools:/app/tools
    environment:
      # Use 0.0.0.0 inside the container
      - NEO4J_URI=bolt://0.0.0.0:7687
      - NEO4J_USERNAME=neo4j
      - NEO4J_PASSWORD=graphrag
      - CHROMA_PERSIST_DIRECTORY=/app/data/chromadb
      # LLM Configuration
      - LLM_ENDPOINT=http://host.docker.internal:1234
      - OLLAMA_ENDPOINT=http://host.docker.internal:11434
      - EMBEDDING_MODEL=snowflake-arctic-embed2:latest
      - RERANKER_MODEL=qllama/bge-reranker-large:latest
      - CONCEPT_MODEL=lmstudio-community/Phi-4-mini-reasoning-MLX-4bit
      - USE_LOCAL_LLM=true
      # Use 0.0.0.0 inside the container
      - GRAPHRAG_API_URL=http://0.0.0.0:5000
      # Add your OpenAI API key here if needed
      # - OPENAI_API_KEY=your_openai_api_key
    restart: unless-stopped