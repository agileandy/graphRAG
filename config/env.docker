# Neo4j Configuration (for Docker)
NEO4J_URI=bolt://0.0.0.0:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=graphrag

# ChromaDB Configuration (for Docker)
CHROMA_PERSIST_DIRECTORY=/app/data/chromadb

# API Configuration (for Docker)
GRAPHRAG_API_PORT=5000
GRAPHRAG_MPC_PORT=8765

# LLM Configuration (for Docker)
# Note: When running in Docker, you'll need to adjust these endpoints
# to point to services accessible from within the container
LLM_ENDPOINT=http://host.docker.internal:1234  # LM Studio on host machine
OLLAMA_ENDPOINT=http://host.docker.internal:11434  # Ollama on host machine
EMBEDDING_MODEL=snowflake-arctic-embed2:latest
RERANKER_MODEL=qllama/bge-reranker-large:latest
CONCEPT_MODEL=lmstudio-community/Phi-4-mini-reasoning-MLX-4bit
USE_LOCAL_LLM=true