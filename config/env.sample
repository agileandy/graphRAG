# Neo4j Configuration
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=graphrag
NEO4J_HOME=/opt/homebrew/bin/neo4j
NEO4J_DATA_DIR=~/.graphrag/neo4j

# ChromaDB Configuration
CHROMA_PERSIST_DIRECTORY=./data/chromadb

# Port Configuration
# API Services
GRAPHRAG_PORT_API=5001                # Main GraphRAG API

# MPC Services
GRAPHRAG_PORT_MPC=8765                # Message Passing Communication server

# MCP Services
GRAPHRAG_PORT_MCP=8767                # Model Context Protocol server
GRAPHRAG_PORT_BUG_MCP=5005            # Bug tracking MCP server

# Database Services
GRAPHRAG_PORT_NEO4J_BOLT=7687         # Neo4j Bolt protocol
GRAPHRAG_PORT_NEO4J_HTTP=7474         # Neo4j HTTP API
GRAPHRAG_PORT_NEO4J_HTTPS=7473        # Neo4j HTTPS API

# Monitoring Services
GRAPHRAG_PORT_PROMETHEUS=9090         # Prometheus metrics
GRAPHRAG_PORT_GRAFANA=3000            # Grafana dashboard

# Docker Port Mappings
# Note: These are the host ports that map to container ports
GRAPHRAG_PORT_DOCKER_NEO4J_BOLT=7688  # Docker mapping for Neo4j Bolt

# LLM Configuration
LLM_ENDPOINT=http://192.168.1.21:1234  # Local LM Studio endpoint for Phi-4
OLLAMA_ENDPOINT=http://localhost:11434  # Local Ollama endpoint
EMBEDDING_MODEL=snowflake-arctic-embed2:latest  # Default embedding model
RERANKER_MODEL=qllama/bge-reranker-large:latest  # Optional reranker model
CONCEPT_MODEL=lmstudio-community/Phi-4-mini-reasoning-MLX-4bit  # Model for concept extraction
USE_LOCAL_LLM=true